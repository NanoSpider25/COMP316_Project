DistilBERT QA Model (Model 6)

This project involves fine-tuning multiple DistilBERT-based models for a Question Answering (QA) system. After testing several versions, Model 6 was selected as the best-performing model based on accuracy and reliability.

What It Does
Takes a question and a context passage

Returns an answer span extracted from the context

Whatâ€™s Included
Code for training, inference, and testing

Multiple trained models

Custom dataset based on Wikipedia-style context

Evaluation done separately

Best Model
Model 6 achieved the best results among the models I trained. It generalizes better and answers more accurately across diverse examples.

Note: Models are currently stored on my drive and not uploaded to this repository.
